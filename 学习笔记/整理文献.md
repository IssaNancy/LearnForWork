# 文献整理

### 基于STTran的文献：

从STTran所对比的模型的文献中进行阅读和分析。

![image-20230317150259038](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230317150259038.png)

![image-20230317150314197](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230317150314197.png)

##### 数据集：Action Genome：

**内容：**

- 476229 **bounding boxes** of 35 **object classes**(without person)
- 1715568 instances of 25 **relationship classes** are annotated for **234253 frames**

- 25 relationship classes are subdivided into 3 different types:
  - **attention relationships**: whether a person is looking at an object
  - **spatial relationships**
  - **contract relationships**

- 135484 subject-object pairs are labeled with spatial relationships
  - (door -->in front of -->person)
  - (person-->eating-->food)

##### 评价指标：

![image-20230317153924596](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230317153924596.png)

1）  PredCLS（给定Ground Truth Object的Bounding boxes，①预测一对Object之间的谓词关系）

2）  SGCLS（给定Ground Truth的Bounding boxes，①给出Bounding boxes的分类，②预测关系标签）

3）  SGDET（给定输入图片或者视频，①检测Object的Bounding boxes和②标签 ，③预测一对Object之间的关系标签）

对于Object，只要IoU高于0.5，则算检测出来了，在召回率前（10，20，50）中进行评估，-->Recall@K（10，20，50）

##### 技术细节：

- **object detection backbone**：Faster RCNN based on RestNet101
- **train the detector**: the training set of Action Genome
- **fair comparison**: 
  - the detector is applied to all baselines 
  - detector的参数包括RPN都是固定的（在训练SGG模型时）
- **nms**:0.4 IoU
- **train model**:
  - optimizer=AdamW
  - 初始学习率=1e-5
  - batch size=1
  - window size：$\eta=2$, stride=1 (for STTran)
  - spatial encoder: 1层
  - temporal decoder: 3层
  - 自注意模块（encoder &decoder）8个头

##### 结果和对比：

- 与基于图像的方法在With Constraint, Semi Constraint 和No Constraint对比

  为了公平比较，所有方法使用相同的detector，提供相同质量的特征图和proposal。

- 加入时间，在所有基于图片的模型上均有提升

- 只有空间 encoder的对比

- 在数据集Action Genome上，STTran是SOTA

##### 消融实验：

- 只有spatial encoder
- spatial encoder+temporal decoder一起

------

##### ！模型对比：

1.所对比的所有方法都采用了同一个**目标检测器**detector（FasterRCNN）【我去仔细看了一下这6篇文献，这6个也不是完全一样，有用FasterRCNN的RestNet101的，也有VGG16的，还有FastRCNN的，不过这些应该无伤大雅吧。】去提取特征和生成proposal，其中大部分的文献都有提到会先将detector进行训练，尽量使所生成的proposal质量相同。

2.**数据集使用情况**：Visual Genome(VG)是这些模型中使用最广泛的数据集，其次就是Visual Relation Detection(VRD),而VRD也是我上次汇报想要复现的BIG模型中使用的其中一个数据集，STTran采用的是Action Genome（AG），这些可以先作为一个备选项数据集，等本周我去下载并详细了解一下其中包含的内容和情况。

3.**评价指标**：

- **STTran**：2021 CVPR

1）  谓词分类PredCLS（给定Ground Truth的标签和Object的Bounding boxes，①预测一对Object之间的谓词关系）

2）  场景图分类SGCLS（给定Ground Truth的Bounding boxes，①给出Bounding boxes的分类，②预测关系标签）

3）  场景图检测SGDET（给定输入图片或者视频，①检测Object的Bounding boxes和②标签 ，③预测一对Object之间的关系标签）

对于Object，只要IoU高于0.5，则算检测出来了，在召回率前（10，20，50）中进行评估，-->Recall@K（10，20，50）

- **GPS-Net**：2020 CVPR（STTran中对比的SOTA模型）

1）同样PredClS，SGCLS，SGDET

2）Recall@K（20，50，100）-->R@(20,50,100)

3）因为VG数据集中的关系分类不均衡，所以也使用了mR@K

- **RelDN**：2019 CVPR

1）同样PredClS，SGCLS，SGDET

2）在OpenImages数据集上使用了mAP和AP

3）在VG数据集上使用了Recall@（20，50，100）

4）在VRD数据集上使用了Recall@（50，100）

针对于不同的数据集在PredClS，SGCLS，SGDET的基础上采取稍微不同的评价方式 



### 基于BIG的文献：

从BIG所对比的模型的文献中进行阅读和分析。

现在的动态场景图生成模型：

1.将视频切割成小片段-->检测每个小片段中的Object轨迹合成一个segment proposals-->对每个proposal中的谓词分类然后组合成预测的

##### 数据集：

- **ImageNet-VidVRD**内容：
  - 包含1000个视频，35个object类别，132个谓词类别
  - 官方分割：800 个视频训练，200个视频测试
- **VidOR**内容：
  - 包含10000个视频，80个object类别，50个谓词类别
  - 官方分割：7000个视频训练，835个视频验证，2165个视频测试
  - 测试集的标签未公布

##### 评价指标：

- 关系检测**RelDet**（Relation Detection）：
  - 检测一系列视觉三元组，以及相应的subject和Object轨迹
  - 判断检测到的三元组是正确的：如果有相同的三元组标记在ground truth中，且subject和Object轨迹的IoU都大于某个阈值如0.5
  - mAP和Recall@K（R@K，K=50，100）
-  关系标注**RelTag**（Relation Tagging）：
  - 只关注视觉关系三元组的精度而忽略了轨迹的定位结果
  - Precision@K（P@K，K=1，5，10）

##### 技术细节：

- **Tracket Detector**
  - object detector：MEGA with backbone ResNet101
  - 生成object轨迹：deep SORT
- VidVRD 只用于Classification stage：BIG-C

##### 结果和对比：

detector：**faster RCNN、MEGA^+^、FGFA**、RefineDet、CascadeRCNN

feathers ：Visual（RoI、I3D、iDT） 、Lang、 Motion 、Mask

RelDet：mAP     R@50    R@100

RelTag:   P@1     P@5      P@10

- 在VidVRD上的对比
  - segment-proposal
  - tracklet-proposal
- 在VidOR上的对比
  - model for Video Relation Understanding challenges

##### 消融实验：

- Base-C: 基于特征的多标签分类，直接对所有轨迹 pairs 进行谓词分类
- Base：Base-C + Grounding stage
- 有无language 特征嵌入
- 有无grounding阶段
- 只有ROI特征

##### **！模型对比：**

1. **数据集**

   **BIG_32**:

   - 使用ILSVRC2016-VID 的训练集和验证集进行评估
   - 选择了1000个视觉关系清晰和丰富的视频
   - 忽视只有单个object和模糊视觉关系的视频
   - 增加了经常出现的object类别，不包含part-of的object之间的关系

2. **评价指标**

   















------











































### **评价指标**：

**STTran**：2021 CVPR

1）  谓词分类PredCLS（给定Ground Truth的标签和Object的Bounding boxes，①预测一对Object之间的谓词关系）

2）  场景图分类SGCLS（给定Ground Truth的Bounding boxes，①给出Bounding boxes的分类，②预测关系标签）

3）  场景图检测SGDET（给定输入图片或者视频，①检测Object的Bounding boxes和②标签 ，③预测一对Object之间的关系标签）

对于Object，只要IoU高于0.5，则算检测出来了，在召回率前（10，20，50）中进行评估，-->Recall@K（10，20，50）

**GPS-Net**：2020 CVPR（STTran中对比的SOTA模型）

1）同样PredClS，SGCLS，SGDET

2）Recall@K（20，50，100）-->R@(20,50,100)

3）因为VG数据集中的关系分类不均衡，所以也使用了mR@K

**RelDN**：2019 CVPR

1）同样PredClS，SGCLS，SGDET

2）在OpenImages数据集上使用了mAP和AP

3）在VG数据集上使用了Recall@（20，50，100）

4）在VRD数据集上使用了Recall@（50，100）

针对于不同的数据集在PredClS，SGCLS，SGDET的基础上采取稍微不同的评价方式 

------



## 问题

1. predcls、sgcls、sgdet之间的**区别**是什么？
2. train detector on training set of Action Genome and get 24.6 mAP at 0.5IoU with **COCO metrics**

------



# 如何读论文







# STTran论文路线梳理

###### **Video Visual Relation Detection**

2017-CCFA-code-32

**Problem**：VidVRD在技术上比ImgVRD更具挑战性，因为在视频领域中，VidVRD在目标的精确跟踪和不同的关系表现方面存在困难。

**Innovation：**

- 作者提出了一种VidVRD方法，该算法包括对象轨迹检测、短期关系预测和greedy关系关联。
- 此作者为VidVRD评估贡献了第一个数据集，其中包含1000个手动标记视觉关系的视频，以验证提出的方法。

**论文理解：**

- 动态视频提供了动态关系的特征，如：follow、towards等

- 提出新的视觉任务VidVRD:视频视觉关系检测

###### Scene Graph Generation from Objects, Phrases and Region Captions

2017-CVPR-code-35

**Problem：**目标检测、场景图生成和区域描述是三个不同语义层次的场景理解任务，场景图是在图像中检测到的目标上生成的，并预测它们之间的成对关系，而区域描述是对目标及其属性、关系等上下文信息的语言描述。为了利用跨语义层次的相互联系，作者提出了一种新的神经网络模型，称为多层次场景描述网络(MSDN)，以**端到端的方式联合解决这三个视觉任务**。

**Motivation：** **目标检测**重点在于检测出一个个单独的物体，**场景图生成**既要识别物体，又要识别物体之间的关系，**区域描述**生成一个自由的句子(包含不确定数量的物体、属性和关系)，而可以利用它们视觉特征的空间和语义相关性去连接这三个任务。

**Innovation：**作者通过引入一个新的框架来对齐三个任务，并引入一个消息传递结构来利用互补效应来实现相互改进，从而共同改进不同语义级别的特征。因此作者提出了一种端到端的多层次场景描述网络(MSDN)，可以同时检测物体，识别它们之间的关系并预测突出图像区域的标题。该模型有效地利用了三个语义层次上丰富的注释及其之间的联系来进行图像理解。

**Contribution：** 作者 1）提出一个新的模型，学习特征不同的语义水平，同时解决三个视觉任务,对象检测、场景图生成和区域描述。2)模型中,给定一个图像,通过对齐物体，短语和区域描述题目在一个图像中构建一个图。3）在图中使用特征细化结构从不同的语义结构来传递消息。

**场景图理解任务**

1. 检测和识别object
2. 估计被object之间的视觉关系
3. 用自由形式的句子描述图像区域。

###### Neural Motifs: Scene Graph Parsing with Global Context

2018-CVPR-code-65

**Problem:**发现了基于数据集Visual Genome的场景图中频繁出现的子结构，引发了对场景图结构规律的分析：不同类型的关系如何与不同的对象相关联，以及高阶图结构如何在不同的场景中重复出现。

**Motivation：**作者分析了基于数据集Visual Genome的场景图中频繁出现的子结构，分析表明：1）对象标签可以高度预测关系标签，反之不然；2）即使在更大的子图中也有重复的模式:一半以上的图包含的主题至少涉及两种关系，

**Innovation：**基于上述分析，1）作者提出了一个新的baseline：给定对象检测，去预测对象对与给定标签之间出现频率最高的关系；2）提出了一个堆叠主题网络（Stacked Motif Networks）去捕捉场景图中的高阶结构和全局交互。

**Contribution：**提出了堆叠主题网络（MOTIFNET），这是一种新的神经网络架构，补充了现有的场景图解析方法。作者认为场景图建模的关键挑战在于设计一种有效的机制来编码全局上下文，该机制可以直接通知局部预测器（即对象和关系）

###### Learning to Compose Dynamic Tree Structures for Visual Contexts

2019-CVPR-code-51

<img src="C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230327182414814.png" alt="image-20230327182414814" style="zoom:80%;" />

**problem：**构建动态树结构将图像中的对象放置到视觉上下文中,帮助视觉推理任务（场景图生成和视觉问答）。

**Motivation：**图像中的对象不是独立存在的，它们处于某种视觉环境中：一种连贯的物体配置，导致它们会共同变化，认知科学的广泛研究表明，我们的大脑天生就利用**视觉环境**来**全面**理解杂乱的视觉场景例如，即使在图中没有完全观察到女孩的腿和马，我们仍然可以推断出“女孩骑马”。

**Innovation：**作者提出了一个**视觉上下文树模型（VCTREE）**，它具有两个关键优势：1）高效且富有表现力的二叉树编码对象之间固有的平行/层次关系，例如，“衣服”和“裤子”通常同时出现，属于“人”；2） 动态结构因图像和任务而异，允许在对象之间传递更多特定于内容/任务的消息。为了构建VCTREE，作者设计了**一个分数函数**，该函数计算每个对象对之间的任务相关有效性，并且该树是分数矩阵中最大生成树的二进制版本。然后，视觉上下文通过双向TreeSTM进行编码，并通过任务特定模型进行解码。作者开发了一种混合学习程序，它集成了最终任务监督学习和树结构强化学习，其中前者的评估结果对后者的结构探索起到了自我批评的作用。

**Contribution：** **提出了VCTREE模型，开创了为高级视觉推理任务（场景图生成（SGG）和视觉问答（VQA））编写对象级视觉上下文编码的动态树结构**。给定图像中的一组对象proposals（假设从Faster RCNN中获得），我们维护对象的可训练任务特定分数矩阵，其中每个条目指示成对对象的上下文有效性。然后，可以从得分矩阵中修剪最大生成树，考虑到“小女孩头上的是什么？”的问题，人头上的对象信息量最大；而考虑到“女孩坐在马上正确吗？”这个问题，整个人的身体更重要。

###### Graphical Contrastive Losses for Scene Graph Parsing

2019-CVPR-code-66

**problem：**场景图解析问题中的错误：**实体实例混淆**，当模型混淆同一类型实体的多个实例时（多个杯子），**近端关系歧义**，当多个主谓-宾语三元组与同一谓语非常接近，并且模型很难推断出正确的主宾配对（音乐家及其乐器的错误配对）

**Motivation：**大多数场景图解析器使用两阶段流水线来检测视觉关系：第一阶段检测实体，第二阶段使用softmax分布预测每个实体对的谓词。在谓词类上只使用交叉熵损失进行训练的此类pip line存在两个常见错误。第一种是实体实例混淆，当模型混淆同一类型实体的多个实例时（例如，多个杯子），第二种是近端关系歧义，当多个主谓-宾语三元组与同一谓语非常接近，并且模型很难推断出正确的主宾配对（例如，音乐家及其乐器的错误配对）。

**Innovation：**1）提出了一组对比损失公式，专门针对场景图解析问题中的这些类型的错误，统称为图形对比损失。这些损失明确地迫使模型通过每种类型的混淆所特有的裕度约束来消除相关和不相关实例的歧义，2）构建了一个的关系检测器RelDN，使用上述pip line来证明提出的损失的有效性。

**Contribution：**提出了解决场景图解析中两个主要问题的方法：实体实例混淆和近端关系歧义。仅谓词类上的softmax分类损失无法充分利用场景图的结构来处理这两个问题。为了解决这个问题，我们提出了图形对比损失，它有效地利用场景图的语义财产来对比积极关系和消极关系。作者又设计了三种类型的损失来解决三个方面的问题。

###### GPS-Net: Graph Property Sensing Network for Scene Graph Generation

2020-CVPR-code-40

![image-20230327195141507](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230327195141507.png)

**problem：**场景图的三个关键属性：边缘方向信息、节点之间的优先级差异和关系的长尾分布

**Motivation：**场景图的多个关键属性被低估了。1）**边缘方向**。边缘方向不仅指示三元组中的主体和对象，而且影响关系的类别。此外，它还会影响对应节点的上下文信息。（如果人和其他对象之间的流动方向相反，上下文的焦点将发生变化，从而影响所有相关节点的上下文信息。这是因为节点的重要性随着它们包含在图中的三元组的数量而变化。）2）图中，腿、狗和人分别涉及两个、三个和四个三元组。因此，考虑到每个节点对该场景图的贡献，**对象检测的优先级**应遵循以下顺序：人>狗>腿。然而，现有的模型通常在场景图中平等地对待所有节点。

**Innovation：**1）提出了一种新的方向感知消息传递（DMP）模块，该模块利用了边缘方向信息。DMP通过以下策略提供特定于节点的上下文信息来增强每个节点的特性。2）提出了一个图形属性感知网络（GPS-Net），该网络充分探索了SGG的三个属性。

**Contribution：**本文通过捕获场景图的三个关键属性，设计了GPS-Net来解决SGG中的主要问题。（1）当通过DMP模块计算节点特定上下文信息时，对边缘方向进行编码；（2） 节点优先级的差异的特征在于新的NPS丢失；（3）通过ARM改进关系频率的使用来缓解关系的长尾分布。













# 知识点记录

###### python常用基本数据结构

- list

  - **基本用法** 列表是一个容器，使用一对中括号`[]`创建一个列表
  - **使用场景** list 使用在需要查询、修改的场景，极不擅长需要频繁插入、删除元素的场景。

- tuple （）

  - 元组是一类不允许添加删除元素的特殊列表，也就是一旦创建后续决不允许增加、删除、修改。

  - **基本用法** 元组大量使用在打包和解包处，如函数有多个返回值时打包为一个元组，赋值到等号左侧变量时解包。

  - **使用场景** 如果非常确定你的对象后面不会被修改，则可以大胆使用元组。为什么？因为相比于list, tuple实例更加节省内存，

  - 创建一个元祖实例

    ```python
    
    t=1,2,3                                         
    type(t) #tuple
    
    from sys import getsizeof                           
    getsizeof(list()) #72 一个list实例占用72个字节
    getsizeof(tuple()) #56 一个tuple实例占用56个字节
    ```

- set {}

  - **基本用法** set是一种里面不能含有重复元素的数据结构，天然使用于列表的去重。

  - **使用场景** 如果只是想缓存某些元素值，且要求元素值不能重复时，适合选用此结构。并且set内允许增删元素，且效率很高。

    **实现原理** set在内部将值哈希为索引，然后按照索引去获取数据，因此删除、增加、查询元素效果都很高。

  - ```python
    # 使用 {} 直接创建集合和使用 set 函数创建集合。
    s= set()# 创建一个空set
    
    s = {"aa"}# 创建set时直接赋一个值
    
    a = "aa"# 可以使用变量
    s = {a}
    
    a=[3,2,5,2,5,3]                                                   b=set(a)    #{2, 3, 5}
    
    a = {2,3,5}                                                       b = {3,4,6,2}                                                     a.intersection(b) # 求交集 {2, 3}                                   
    ```

- dict  {}

  - **基本用法** dict 是Python中使用最频繁的数据结构之一，字典创建由通过dict函数、{}写法、字典生成式等，增删查元素效率都很高。

  - **使用场景** 字典尤其适合在查询多的场景，时间复杂度为O(1). 如leetcode第一题求解两数之和时，就会使用到dict的O(1)查询时间复杂度。

  - **实现原理** 字典是一种哈希表，同时保存了键值对。

  - 同时，Python类中属性值等信息也都是缓存在`__dict__`这个字典型数据结构中。

  - ```python
    d = {'a':1,'b':2} # {}创建字典
    
    # 列表生成式
    d = {a:b for a,b in zip(['a','b'],[1,2])}                            
    d  # {'a': 1, 'b': 2}  
    ```

###### torch

torch.mode()返回给定维 dim 上的众数值，同时返回一个包含众数值的索引 LongTensor。

```python
torch.mode(input, dim=-1, values=None, indices=None) -> (Tensor, LongTensor)
```

torch.arange() 

```python
arange(start=0, end, step=1, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor

#     >>> torch.arange(5)  # 默认以 0 为起点
    tensor([ 0,  1,  2,  3,  4])
    >>> torch.arange(1, 4)  # 默认间隔为 1
    tensor([ 1,  2,  3])
    >>> torch.arange(1, 2.5, 0.5)  # 指定间隔 0.5
    tensor([ 1.0000,  1.5000,  2.0000])

```

torch.rand() 均匀分布

![image-20230322191506491](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230322191506491.png)

torch.randn() 标准正态分布

<img src="C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230322191625947.png" alt="image-20230322191625947" style="zoom: 67%;" />

虽然randn和normal都可以生成服从正态分布的随机数，但是normal可以自己设定均值和标准差。

###### 非最大值抑制

(Non-Maximal Suppression，NMS)的技巧，它会根据两个预测边界框之间的 IoU 选择最佳边界框

**步骤：**

1. 查看每个网格单元的输出向量。每个网格单元将具有一个带有Pc值和边界框坐标的输出矢量。
2. 删除所有Pc值小于或等于某个阈值（例如0.5）的边界框。因此，如果有超过50％置信度，我们将保留这个边界框。
3. 选择具有最高Pc值的边界框。
4. 删除所有与当前编辑框具有高IoU 的边界框，并在最后一步中选中该框。

###### copy和deepcopy

- **存储方式**

  <img src="D:\picture\021d5245feca4f1c955208a0f07644c6.png" alt="021d5245feca4f1c955208a0f07644c6" style="zoom: 50%;" />

如上图所示，用户看到的是 lista的4个元素值，但是内存中保存的却是4个元素地址。

当元素是列表时，第一层保存的是列表的地址，第二层保存的是列表元素的地址，第三层才是列表的值。当元素是字典的时候，与列表类似。

- **列表修改已有值**

<img src="D:\picture\9e6273ce61e34e34a521bf696f72d1d2.png" alt="9e6273ce61e34e34a521bf696f72d1d2" style="zoom:50%;" />

**列表整体重新赋值**

<img src="D:\picture\87f5dce8ca8e483aafaf9a81b7be5c68.png" alt="87f5dce8ca8e483aafaf9a81b7be5c68" style="zoom:50%;" />

- **浅层copy**

  <img src="D:\picture\76e6a64cbbda46a6b617a8fdb31bae2a.png" alt="76e6a64cbbda46a6b617a8fdb31bae2a" style="zoom:50%;" />

- **区别**

  copy：不管多么复杂的数据结构，浅拷贝都只会copy一层。

  deepcopy：将整个变量内存全部复制一遍，新变量与原变量没有任何关系。

  ```python
  import copy
  
  a = [1, 2, 3, 4, ['a', 'b']]
  b = a
  c = copy.copy(a)
  d = copy.deepcopy(a)
  
  a.append(5)
  a[1] = 20
  a[4].append('c')
  del a[0]
  # b也引用的a的地址，两者引用的内存地址是一样的。因此b和a的关系是紧密相连的，一模一样。可以通过 id(a) 和id(b)比较，两者是一样的。
  
  '''由于c是浅拷贝的a列表，因此只copy了第一层，也就是地址层。所以，当a.append(5)时，新增了一个内存块，但是c只有前5个内存块，因此c没有变化。继续a修改了a[1]，然而这个值是属于第一层，已经copy给了c，因此c也没有变化。继续a修改了子列表，这个时候a复制给c的只是列表的地址，且a中的子列表地址和c中的子列表地址是指向同一个地方的，因此修改了a中子列表，c中的子列表也会相应的改变。最后删除a[0]，与修改a[1]一致，与c无关。'''
  '''
  由于d是深拷贝的a列表，因此d是将a的地址和值一并复制过来，与a没有半点关系，也就是说d和a是两个完全独立的内存块，没有任何交集。因此，后面a的任意修改都与d无关
  '''
  print(a) # [20,3,4,[‘a’,‘b’,‘c’],5]
  print(b)# [20,3,4,[‘a’,‘b’,‘c’],5]
  print(c)# [1,2,3,4,[‘a’,‘b’,‘c’]]
  print(d)# [1,2,3,4,[‘a’,‘b’]]
  # copy只是拷贝了第一层，而deepcopy才是拷贝的全部数据。备份列表需要使用deepcopy，而不是简单的copy。
  ```

  

###### cv2 RGB和BGR互换

- RGB：PIL，日常图片存储

- BGR：opencv，caffe

- 转换方法：

  1. > img = cv2.imread("001.jpg")
     >
     > img_ = img[:,:,::-1].transpose((2,0,1))

     ① 在opencv里，图格式HWC，其余都是CHW，故transpose((2,0,1))

     ② img[:,:,::-1]对应H、W、C，彩图是3通道，即C是3层。opencv里对应BGR，故通过C通道的 ::-1 就是把BGR转为RGB

     注： [::-1] 代表顺序相反操作

     ③ 若不涉及C通道的BGR转RGB，如Img[:,:,0]代表B通道，也就是蓝色分量图像；Img[:,:,1]代表G通道，也就是绿色分量图像；Img[:,:,2]代表R通道，也就是红色分量图像。

  2. 使用opencv自带函数转换图像的R通道和B通道。

     RGB -> BGR

     > img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)

     BGR->RGB

     > img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)

  3. BRG转RGB

     > rgb = bgr[...,::-1]

     RGB转BGR

     > bgr = rgb[...,::-1]

     RGB转GBR

     > gbr = rgb[...,[2,0,1]]

###### tqdm

是python的进度条库，可以在 Python长循环中添加一个进度提示信息。用户只需要封装任意的迭代器，是一个快速、扩展性强的进度条工具库。

```python
# 使用方法
import time
from tqdm import *

for i in tqdm(range(100)):
    time.sleep(0.01)
--------------------------------------
# 简单写法
# trange(i)：tqdm(range(i))的简单写法
for t in trange(100):
    time.sleep(0.01)
--------------------------------------
# update()方法手动控制进度条更新的进度
with tqdm(total=200) as pbar:
    for i in range(20):  # 总共更新 20 次
        pbar.update(10)  # 每次更新步长为 10
        time.sleep(1)
# 或者
pbar = tqdm(total=200)

for i in range (20):
    pbar.update(10)
    time.sleep(1)

pbar.close()
--------------------------------------
# write()方法
pbar = trange(10)

for i in pbar:
    time.sleep(1)
    if not (i % 3):
        tqdm.write('Done task %i' %i)
--------------------------------------
# 通过set_description()和set_postfix()设置进度条显示信息
from random import random,randint

with trange(10) as t:
    for i in t:                
        t.set_description("GEN %i"%i)  # 进度条左边显示信息        
        t.set_postfix(loss=random(), gen=randint(1,999), str="h", lst=[1,2])  # 进度条右边显示信息
        time.sleep(0.1)  
```

###### Linux unzip

unzip命令用于解压缩由zip命令压缩的“.zip”压缩包

```python
unzip [-cflptuvz][-agCjLMnoqsVX][-P <密码>][.zip文件][文件][-d <目录>][-x <文件>] 或 unzip [-Z]
```

![image-20230319155244817](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230319155244817.png)

**常用命令：**

```python
# 查看压缩文件中包含的文件：
unzip -l 压缩文件名
# 查看压缩文件的目录信息：
unzip -v 压缩文件名
# 解压到当前文件夹
unzip 压缩文件名
# 解压到指定文件夹
unzip 压缩文件名 -d 指定目录
# 解压到指定文件夹，不覆盖已经存在的
unzip -n 压缩文件名 -d 指定目录
# 解压到指定文件夹，覆盖已经存在的
unzip -o 压缩文件名 -d 指定目录
```



###### pandas

pandas 是基于Numpy的一种工具，该工具是为了解决数据分析任务而创建的。

**Serious：**一维数组，与Numpy中的一维array类似。二者与Python中基本的数据结构List也很相似。Serious能保存不同种数据类型。 
**DataFrame：**二维的表格型数据结构

###### 3D卷积

3D卷积与2D卷积的区别:多了一个时间维度

3D:3 x 3 x 4, 4表示一个序列中有4帧图像,这4帧图像具有时间上的关系,与batch不同概念

UCF101数据集网址:https://www.crcv.ucf.edu/data/UCF101.php

速度太慢的话,换网址:

cat UCF-101* > UCF-101.zip

###### torch.nn.init

**`torch.nn.init.uniform_(tensor, a=0.0, b=1.0)`** 均匀分布

**`torch.nn.init.normal_(tensor, mean=0.0, std=1.0)`**正态分布

###### torch.nn

**nn.Linear():全连接层**

是用于设置网络中的**全连接层的**，需要注意在**二维图像处理的任务中**，**全连接层的输入与输出一般都设置为二维张量**，形状通常为`[batch_size, size]`，`不同于卷积层要求输入输出是四维张量`。其用法与形参说明如下：

![image-20230322190729835](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230322190729835.png)

- `in_features`指的是**输入的二维张量的大小**，即输入的 **[batch_size, size]** 中的`size`（**输入图片的特征共有多少个，上一个全连接层神经元的个数**）。



- `out_features`指的是**输出的二维张量的大小**，即输出的二维张量的形状为`[batch_size，output_size]`，当然，它也代表了**该全连接层的神经元个数**。
- 从**输入输出的张量的shape角度来理解**，相当于一个`输入为[batch_size, in_features]`的张量变`换成了[batch_size, out_features]的输出张量`。

**nn.Laynormal()**

LayerNorm中不会像BatchNorm那样跟踪统计全局的均值方差，因此train()和eval() 对LayerNorm没有影响。

```python
torch.nn.LayerNorm(
        normalized_shape: Union[int, List[int], torch.Size],
    	# 如果传入整数，比如4，则被看做只有一个整数的list，此时LayerNorm会对输入的最后一维进行归一化，这个int值需要和输入的最后一维一样大。
    	# 如果输入的是个list或者torch.Size，比如[3, 4]或torch.Size([3, 4])，则会对网络最后的两维进行归一化，且要求输入数据的最后两维尺寸也是[3, 4]。
        eps: float = 1e-05,
        elementwise_affine: bool = True)
```

**nn.Conv2d:二维卷积运算**

功能：对多个输⼊平⾯组成的输⼊信号应⽤2D卷积运算，常⽤于图像处理。

![image-20230319085551094](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230319085551094.png)

**nn.BatchNorm2d():**

功能：对输⼊的四维数组进⾏批量标准化处理

对于所有的batch中样本的同⼀个channel的数据元素进⾏标准化处理，即如果有C个通 道，⽆论batch中有多少个样本，都会在通道维度上进⾏标准化处理，⼀共进⾏C次。

![image-20230319085652510](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230319085652510.png)

###### 卷积神经网络

**输⼊层**:3种常⽤的数据处理⽅式 

- 去均值:把输⼊数据各个维度都中⼼化到0(中⼼平移到原点) 
- 归⼀化:幅度归⼀化到同样的范围(X/Y范围相同) 
- PCA/⽩化:PCA降维/⽩化湿对数据每个特征轴上的幅度归⼀化 图像数据只去均值,不做其他 

**卷积层**: 深度depth是指这⼀层神经元的个数,每⼀个神经元会得到⼀个特征图(矩阵),所以有 多少神经元就有多少层.步长stride是指每次滑动的格⼦数,填充值zero-padding

![image-20230319090007719](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230319090007719.png)

![image-20230319090029375](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230319090029375.png)

**池化层(下采样层)** 

- 夹在连续的卷积层中间 
- 压缩数据和参数的量,减少过拟合

**卷积计算**

![image-20230319090150079](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230319090150079.png)

输⼊的channel:3 隐藏在kernal中:5 5 3 

这⼀层的卷积层的参数为:5 5 3 5.因为每⼀个neuron所使⽤的参数相同,⼀个神经元参数为:5 5 3.

计算公式：![image-20230319090250470](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230319090250470.png)

![image-20230319090311517](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230319090311517.png)

pooling不改变channel 只改变shape 

**迁移学习**,当数据量较少以及任务内容接近时可以使⽤其他模型的参数来初始化⾃⼰的模型

###### NLP

![image-20230319090417454](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230319090417454.png)

词典是集合,⽆序的;语料库是序列,有序的.

###### 目标检测

评价检测任务的指标:IoU mAP

mAP@.75 means the mAP with IoU=0.75

ROI pooling把形状⼤⼩不⼀的特征图变成形状⼤⼩⼀样的特征图(特征维度的规范化),⽅便 后⾯进⾏fc

**Fast RCNN**

![image-20230319090615558](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230319090615558.png)

ROI Align是为了解决ROI pooling 精度丢失的问题 

Faster RCNN和Fast RCNN 的区别:Faster的区域推荐是使⽤的基于CNN的RPN解决的,⽽ Fast是使⽤Selective Search ⼀个⾮深度学习的组件 实现的 

RPN:anchor是对应到原图的

**Faster RCNN**

![image-20230319090719327](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230319090719327.png)

**Mask RCNN** 除了做检测还可以做分割

![image-20230319090743832](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230319090743832.png)

**2Stage ⽹络**:因为有⼀个RPN region proposal的存在,先⽣成⼀个region proposal,再去做检 测--->2 stage 

**感受野**：卷积神经⽹络每⼀层输出的特征图（feature map）上的像素点在原始图像上映射 的区域⼤⼩。

###### pathlib的path():

- 获取路径

```python
from pathlib import Path

#获取当前目录
current_path = Path.cwd()
# 获取 home 目录
home_path = Path.home()
# 绝对路径
print(Path(".").resolve())
path = Path(r"E:\lever\dataset\lever_01\front/000001.jpg")
## 将Windows 路径分隔符 "\" 改为 Unix "/"
path.as_posix()
# 获取父级目录
parent_path = path.parent
```

- 文件名字操作

```python
from pathlib import Path

path = Path(r"E:\lever\dataset\lever_01\front/000001.jpg")

print("路径分割：", path.parts)  ## 结果为一个元组
print("文件名字(带扩展名)：", path.name)
print("文件扩展名：", path.suffix)
print("文件名(不带扩展名)：", path.stem)
print("更改路径后缀：", path.with_suffix(".json"))
print("更改路径文件名：", path.with_name("img_1.jpg"))

path = Path(r"E:\lever\dataset\lever_01\front/000001.jpg.txt")
print("扩展名列表", path.suffixes)

'''
路径分割： (‘E:\’, ‘lever’, ‘dataset’, ‘lever_01’, ‘front’, ‘000001.jpg’)
文件名字(带扩展名)： 000001.jpg
文件扩展名： .jpg
文件名(不带扩展名)： 000001
更改路径后缀： E:\lever\dataset\lever_01\front\000001.json
更改路径文件名： E:\lever\dataset\lever_01\front\img_1.jpg
扩展名列表 [’.jpg’, ‘.txt’]
```

- 路径的判断

```py
from pathlib import Path

path = Path(r"E:\lever\dataset\lever_01\front/000001.jpg")
print("是否为文件：", path.is_file())
print("是否为文件夹：", path.is_dir())
print("是否存在该路径：", path.exists())
print("是否为绝对路径：", path.is_absolute())
'''
是否为文件： True
是否为文件夹： False
是否存在该路径： True
是否为绝对路径： True
'''

```

- 获取路径下的文件以及目录

```py
from pathlib import Path

path = Path("data")

for p in path.iterdir(): ## 获取路径下所有文件及文件夹
    print(p)

print("===================")

for p in path.glob("*.*"): ## 按匹配模式获取所要的文件
    print(p)

print("===================")

for p in path.glob("**/*"):
    print(p)

print("===================") ## 递归遍历子目录及文件

for p in path.rglob("*"):
    print(p)

```

- 路径的拼接:

  1.直接用 `/` 斜杠拼接路径

  2.使用 `joinpath` 来拼接

  ```py
  from pathlib import Path
  
  path = Path("data")
  
  print(path.joinpath("test1", "1.txt"))
  print(path / "1.txt")
  ```

- 删除文件以及文件夹

  ```py
  from pathlib import Path
  
  # 删除文件
  path = Path("data/1.txt")
  path.unlink()
  
  # 删除文件夹 （必须是空文件夹）
  path_dir = Path("data/test2")
  path.rmdir()
  ```

###### **os.listdir()用法**:

**获取指定文件夹下的所有文件**

- os.path.isdir()用于判断对象是否为一个目录。
- os.path.splitext()：分离文件名与扩展名
- 用os.listdir读取到的文件路径是乱序的，调用list.sort()函数可以对文件按顺序排序。

sudo find ./ -name ".DS_Store" -depth -exec rm {} \;删除文件夹中的.DS_Store文件

###### os.path常用模块:

- os.path.sep:路径分隔符 linux下就用这个了’/’

  os.path.altsep: 根目录

  os.path.curdir:当前目录

  os.path.pardir：父目录

  os.path.abspath(path)：绝对路径

  os.path.join(): 常用来链接路径

  os.path.split(path): 把path分为目录和文件两个部分，以列表返回

###### **可视化**

- **tensorboard:**

  - 安装tensorboard:

    pip install tensorboard -i https://pypi.doubanio.com/simple

  - 可视化两步骤:
    - 在代码中需要将可视化的数据写入磁盘(文件位置)
    - 在命令行中打开tensorboard,并指定写入的文件位置,进行可视化

```python
# SummaryWriter是一个可以写入磁盘的工具
from torch.utils.tensorboard import SummaryWriter
# 初始化一个writer来完成写入操作
writer=SummaryWriter('写入的位置(当前目录下的)') 
'''
img的shape=torch.size([3,32,242])
变成npImg=img.permute(1,2,0).numpy()
plt.imshow(npimg)
'''
# 动态显示:
imgs=(images[-8:])
writer.add_image('name',imgs)
#显示模型:
writer.add_graph(model,imgs)
#打开方式:
tensorboard --logdir "文件名"
#动态显示训练过程中的loss和acc的变化
#将标量数据写入
writer.add_scalar('train_loss',epoch_loss,epoch+1)
```















###### 小知识点：

:label:IOU:两个框的交并比,两框交叠的面积除以并起来的面积

**:label:isinstance(object, class):判断object, class的变量类型是否相同**

**:label:os.path.isfile(path) 函数判断某一路径是否为文件**

**:label:torch.load()作用:用来加载torch.save() 保存的模型文件**

**:label:os.path.basename()返回path最后的文件名,若path以/或\结尾则返回空值**

**:label:a=array.array('d'):![image-20230319085125810](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230319085125810.png)**

![image-20230319085217953](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230319085217953.png)







# 代码提升

###### 手写数字识别

```python
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader
import torchvision.datasets as datasets
import torchvision.transforms as transforms
from tqdm import tqdm

class CNN(nn.Module):
    def __init__(self,in_channels=1,num_classes=10):
        super().__init__()
        self.conv1 = nn.Conv2d(in_channels=1,out_channels=8,kernel_size=(3,3),stride=(1,1),padding=(1,1))
        self.pool = nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))
        self.conv2 = nn.Conv2d(in_channels=8,out_channels=16,kernel_size=(3,3),stride=(1,1),padding=(1,1))
        self.fc1 = nn.Linear(16*7*7,num_classes)
    def forward(self,x):
        x = F.relu(self.conv1(x))
        x = self.pool(x)
        x = F.relu(self.conv2(x))
        x = self.pool(x)
        x = x.reshape(x.shape[0],-1)
        x = self.fc1(x)
        return x

device = torch.device("cuda"if torch.cuda.is_available() else "cpu")

in_channels = 1
num_classes = 10
learning_rate = 0.001
batch_size = 64
num_epochs = 5

train_dataset = datasets.MNIST(root="dataset/",train=True,transform=transforms.ToTensor(),download=True)
train_loader = DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)

test_dataset = datasets.MNIST(root="dataset/",train=False,transform=transforms.ToTensor(),download=True)
test_loader = DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)

model = CNN().to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(),lr=learning_rate)

for index,（data,targets） in tqdm(enumerate(train_loader),total=len(train_loader),leave = True):
    for data,targets in tqdm(train_loader):
        # Get data to cuda if possible
        data = data.to(device=device)
        targets = targets.to(device=device)

        # forward
        scores = model(data)
        loss = criterion(scores,targets)

        # backward
        optimizer.zero_grad()
        loss.backward()

        # gardient descent or adam step
        optimizer.step()
```

# 代码工具

###### 创建文件夹

```python
import os
def makedir(new_dir):
    if not os.path.exists(new_dir):
        os.makedirs(new_dir)
```

###### 设置transform

```python
train_transform= transforms.Compose([
    transforms.Resize((32,32)),
    transforms.RandomCrop(32,padding=4),
    transforms.ToTensor(),
])
```

dataset是用户自己创建的，类中必须重写 __ getitem __(self,index)函数

###### tensor数据升维

```python
arr = arr.unsqueeze(0)  [3,5,5]-----> [1, 3, 5, 5]
```



###### 数据集取小

```python
        if datasize == 'mini':
            small_person = {}
            small_object = {}
            # for i in list(person_bbox.keys())[:10000]:  # 自己改的
            for i in list(person_bbox.keys())[:80000]:
                small_person[i] = person_bbox[i]
                small_object[i] = object_bbox[i]
            person_bbox = small_person
            object_bbox = small_object
```

###### Transformer

encoder：

```python
    B, Nt, E = q.shape
    q = q / math.sqrt(E)
    # (B, Nt, E) x (B, E, Ns) -> (B, Nt, Ns)
    attn = torch.bmm(q, k.transpose(-2, -1))
    if attn_mask is not None:
        attn += attn_mask
    attn = softmax(attn, dim=-1)
    if dropout_p > 0.0:
        attn = dropout(attn, p=dropout_p)
    # (B, Nt, Ns) x (B, Ns, E) -> (B, Nt, E)
    output = torch.bmm(attn, v)
    return output, attn
————————————————————————————————————————————————————————————————————————
    attn_output, attn_output_weights = _scaled_dot_product_attention(q, k, v, attn_mask, dropout_p)
    attn_output = attn_output.transpose(0, 1).contiguous().view(tgt_len, bsz, embed_dim)
    attn_output = linear(attn_output, out_proj_weight, out_proj_bias)

    if need_weights:
        # average attention weights over heads
        attn_output_weights = attn_output_weights.view(bsz, num_heads, tgt_len, src_len)
        return attn_output, attn_output_weights.sum(dim=1) / num_heads
```

# Git

###### 安装

在Windows上使用Git，可以从Git官网直接[下载安装程序](https://git-scm.com/downloads)，然后按默认选项安装即可。

安装完成后，在开始菜单里找到“Git”->“Git Bash”，蹦出一个类似命令行窗口的东西，就说明Git安装成功！

![install-git-on-windows](https://www.liaoxuefeng.com/files/attachments/919018718363424/0)

安装完成后，还需要最后一步设置，在命令行输入：

```bash
$ git config --global user.name "Nancy"
$ git config --global user.email "2353527049@qq.com"
```

注意`git config`命令的`--global`参数，用了这个参数，表示你这台机器上所有的Git仓库都会使用这个配置，当然也可以对某个仓库指定不同的用户名和Email地址。

###### 创建版本库**repository**

第一步，选择一个合适的地方，创建一个空目录：

```bash
$ mkdir git_repository
$ cd git_repository
$ 当前地址
D:\git_respository
```

第二步，通过`git init`命令把这个目录变成Git可以管理的仓库：

```bash
$ git init
Initialized empty Git repository in D:/git_respository/.git/
```

瞬间Git就把仓库建好了，而且告诉你是一个空的仓库（empty Git repository），当前目录下多了一个`.git`的目录，这个目录是Git来跟踪管理版本库的，没事不要手动修改这个目录里面的文件，不然改乱了，就把Git仓库给破坏了。

如果没有看到`.git`目录，那是因为这个目录默认是隐藏的，用`ls -ah`命令就可以看见。

现在我们编写一个`readme.txt`文件，内容如下：

```
Git is a version control system.
Git is free software.
```

一定要放到`git_respository`目录下（子目录也行），因为这是一个Git仓库，放到其他地方Git再厉害也找不到这个文件。

把一个**文件放到Git仓库**只需要两步。

第一步，用命令`git add`告诉Git，把文件添加到仓库：

```
$ git add readme.txt
```

执行上面的命令，没有任何显示，这就对了，Unix的哲学是“没有消息就是好消息”，说明添加成功。

第二步，用命令`git commit`告诉Git，把文件提交到仓库：

```bash
$ git commit -m "wrote a readme file"
[master (root-commit) eaadf4e] wrote a readme file
 1 file changed, 2 insertions(+)
 create mode 100644 readme.txt
```

简单解释一下`git commit`命令，`-m`后面输入的是本次提交的说明，可以输入任意内容，当然最好是有意义的，这样你就能从历史记录里方便地找到改动记录。

嫌麻烦不想输入`-m "xxx"`行不行？确实有办法可以这么干，但是强烈不建议你这么干，因为输入说明对自己对别人阅读都很重要。实在不想输入说明的童鞋请自行Google，我不告诉你这个参数。

`git commit`命令执行成功后会告诉你，`1 file changed`：1个文件被改动（我们新添加的readme.txt文件）；`2 insertions`：插入了两行内容（readme.txt有两行内容）。

为什么Git添加文件需要`add`，`commit`一共两步呢？因为`commit`可以一次提交很多文件，所以你可以多次`add`不同的文件，比如：

```bash
$ git add file1.txt
$ git add file2.txt file3.txt
$ git commit -m "add 3 files."
```

**疑难解答**

Q：输入`git add readme.txt`，得到错误：`fatal: not a git repository (or any of the parent directories)`。

A：Git命令必须在Git仓库目录内执行（`git init`除外），在仓库目录外执行是没有意义的。

Q：输入`git add readme.txt`，得到错误`fatal: pathspec 'readme.txt' did not match any files`。

A：添加某个文件时，该文件必须在当前目录下存在，用`ls`或者`dir`命令查看当前目录的文件，看看文件是否存在，或者是否写错了文件名。

**小结**

现在总结一下今天学的两点内容：

初始化一个Git仓库，使用`git init`命令。

添加文件到Git仓库，分两步：

1. 使用命令`git add <file>`，注意，可反复多次使用，添加多个文件；
2. 使用命令`git commit -m <message>`，完成。

###### 远程仓库

第1步：创建SSH Key。在用户主目录下，看看有没有.ssh目录，如果有，再看看这个目录下有没有`id_rsa`和`id_rsa.pub`这两个文件，如果已经有了，可直接跳到下一步。如果没有，打开Shell（Windows下打开Git Bash），创建SSH Key：

```
$ ssh-keygen -t rsa -C "2353527049@qq.com"
```

![image-20230324210330735](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230324210330735.png)

第2步：登陆GitHub，打开“Account settings”，“SSH Keys”页面：

然后，点“Add SSH Key”，填上任意Title，在Key文本框里粘贴`id_rsa.pub`文件的内容：

![github-addkey-1](https://www.liaoxuefeng.com/files/attachments/919021379029408/0)

点“Add Key”，你就应该看到已经添加的Key：

![image-20230324210658823](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230324210658823.png)

![image-20230324210724921](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230324210724921.png)

你需要把邮件地址换成你自己的邮件地址，然后一路回车，使用默认值即可，由于这个Key也不是用于军事目的，所以也无需设置密码。

如果一切顺利的话，可以在用户主目录里找到`.ssh`目录，里面有`id_rsa`和`id_rsa.pub`两个文件，这两个就是SSH Key的秘钥对，`id_rsa`是私钥，不能泄露出去，`id_rsa.pub`是公钥，可以放心地告诉任何人。

###### 添加远程库

现在的情景是，你已经在本地创建了一个Git仓库后，又想在GitHub创建一个Git仓库，并且让这两个仓库进行远程同步，这样，GitHub上的仓库既可以作为备份，又可以让其他人通过该仓库来协作，真是一举多得。

首先，登陆GitHub，然后，在右上角找到“Create a new repo”按钮，创建一个新的仓库：

![github-create-repo-1](https://www.liaoxuefeng.com/files/attachments/919021631860000/0)

在Repository name填入`LearnForWork`，其他保持默认设置，点击“Create repository”按钮，就成功地创建了一个新的Git仓库：

![github-create-repo-2](https://www.liaoxuefeng.com/files/attachments/919021652277920/0)

目前，在GitHub上的这个`LearnForWork`仓库还是空的，GitHub告诉我们，可以从这个仓库克隆出新的仓库，也可以把一个已有的本地仓库与之关联，然后，把本地仓库的内容推送到GitHub仓库。

现在，我们根据GitHub的提示，在本地的`LearnForWork`仓库下运行命令：

```
$ git remote add origin git@github.com:IssaNancy/LearnForWork.git
```

请千万注意，把上面的`michaelliao`替换成你自己的GitHub账户名，否则，你在本地关联的就是我的远程库，关联没有问题，但是你以后推送是推不上去的，因为你的SSH Key公钥不在我的账户列表中。

添加后，远程库的名字就是`origin`，这是Git默认的叫法，也可以改成别的，但是`origin`这个名字一看就知道是远程库。

```bash
$ git push origin master -f //强行让本地分支覆盖远程分支
```

下一步，就可以把本地库的所有内容推送到远程库上：

```bash
$ git push -u origin master
Counting objects: 20, done.
Delta compression using up to 4 threads.
Compressing objects: 100% (15/15), done.
Writing objects: 100% (20/20), 1.64 KiB | 560.00 KiB/s, done.
Total 20 (delta 5), reused 0 (delta 0)
remote: Resolving deltas: 100% (5/5), done.
To github.com:michaelliao/learngit.git
 * [new branch]      master -> master
Branch 'master' set up to track remote branch 'master' from 'origin'.
```

把本地库的内容推送到远程，用`git push`命令，实际上是把当前分支`master`推送到远程。

由于远程库是空的，我们第一次推送`master`分支时，加上了`-u`参数，Git不但会把本地的`master`分支内容推送的远程新的`master`分支，还会把本地的`master`分支和远程的`master`分支关联起来，在以后的推送或者拉取时就可以简化命令。

推送成功后，可以立刻在GitHub页面中看到远程库的内容已经和本地一模一样：

![github-repo](https://www.liaoxuefeng.com/files/attachments/919021675995552/0)

从现在起，只要本地作了提交，就可以通过命令：

```
$ git push origin master
```

把本地`master`分支的最新修改推送至GitHub，现在，你就拥有了真正的分布式版本库！

$ git pull :命令用于从另一个存储库或本地分支获取并集成(整合).作用:取回远程主机某个分支的更新,再与本地的指定分支合并

使用语法:
git pull [options][][<refspec>..]
$ git fetch：相当于是从远程获取最新版本到本地，不会自动合并。

2. 如果还想要远程分支上的提交:
git新版本的使用旧的pull命令:git pull origin master并不会解决问题,需要改为:

```bash
git pull origin master --allow-unrelated-histories 
```

**SSH警告**

当你第一次使用Git的`clone`或者`push`命令连接GitHub时，会得到一个警告：

```
The authenticity of host 'github.com (xx.xx.xx.xx)' can't be established.
RSA key fingerprint is xx.xx.xx.xx.xx.
Are you sure you want to continue connecting (yes/no)?
```

这是因为Git使用SSH连接，而SSH连接在第一次验证GitHub服务器的Key时，需要你确认GitHub的Key的指纹信息是否真的来自GitHub的服务器，输入`yes`回车即可。

Git会输出一个警告，告诉你已经把GitHub的Key添加到本机的一个信任列表里了：

```
Warning: Permanently added 'github.com' (RSA) to the list of known hosts.
```

这个警告只会出现一次，后面的操作就不会有任何警告了。

如果你实在担心有人冒充GitHub服务器，输入`yes`前可以对照[GitHub的RSA Key的指纹信息](https://help.github.com/articles/what-are-github-s-ssh-key-fingerprints/)是否与SSH连接给出的一致。

###### 删除远程库

如果添加的时候地址写错了，或者就是想删除远程库，可以用`git remote rm <name>`命令。使用前，建议先用`git remote -v`查看远程库信息：

```
$ git remote -v
origin  git@github.com:michaelliao/learn-git.git (fetch)
origin  git@github.com:michaelliao/learn-git.git (push)
```

然后，根据名字删除，比如删除`origin`：

```
$ git remote rm origin
```

此处的“删除”其实是解除了本地和远程的绑定关系，并不是物理上删除了远程库。远程库本身并没有任何改动。要真正删除远程库，需要登录到GitHub，在后台页面找到删除按钮再删除。

**小结**

要关联一个远程库，使用命令`git remote add origin git@server-name:path/repo-name.git`；

关联一个远程库时必须给远程库指定一个名字，`origin`是默认习惯命名；

关联后，使用命令`git push -u origin master`第一次推送master分支的所有内容；

此后，每次本地提交后，只要有必要，就可以使用命令`git push origin master`推送最新修改；

###### 分支管理

首先，我们创建`dev`分支，然后切换到`dev`分支：

```
$ git checkout -b dev
Switched to a new branch 'dev'
```

`git checkout`命令加上`-b`参数表示创建并切换，相当于以下两条命令：

```
$ git branch dev
$ git checkout dev
Switched to branch 'dev'
```

然后，用`git branch`命令查看当前分支：

```
$ git branch
* dev
  master
```

`git branch`命令会列出所有分支，当前分支前面会标一个`*`号。

然后，我们就可以在`dev`分支上正常提交，比如对`readme.txt`做个修改，加上一行：

```
Creating a new branch is quick.
```

然后提交：

```
$ git add readme.txt 
$ git commit -m "branch test"
[dev b17d20e] branch test
 1 file changed, 1 insertion(+)
```

现在，`dev`分支的工作完成，我们就可以切换回`master`分支：

```
$ git checkout master
Switched to branch 'master'
```

切换回`master`分支后，再查看一个`readme.txt`文件，刚才添加的内容不见了！因为那个提交是在`dev`分支上，而`master`分支此刻的提交点并没有变：

![git-br-on-master](https://www.liaoxuefeng.com/files/attachments/919022533080576/0)

现在，我们把`dev`分支的工作成果合并到`master`分支上：

```
$ git merge dev
Updating d46f35e..b17d20e
Fast-forward
 readme.txt | 1 +
 1 file changed, 1 insertion(+)
```

`git merge`命令用于合并指定分支到当前分支。合并后，再查看`readme.txt`的内容，就可以看到，和`dev`分支的最新提交是完全一样的。

注意到上面的`Fast-forward`信息，Git告诉我们，这次合并是“快进模式”，也就是直接把`master`指向`dev`的当前提交，所以合并速度非常快。

当然，也不是每次合并都能`Fast-forward`，我们后面会讲其他方式的合并。

合并完成后，就可以放心地删除`dev`分支了：

```
$ git branch -d dev
Deleted branch dev (was b17d20e).
```

删除后，查看`branch`，就只剩下`master`分支了

```
$ git branch
* master
```

因为创建、合并和删除分支非常快，所以Git鼓励你使用分支完成某个任务，合并后再删掉分支，这和直接在`master`分支上工作效果是一样的，但过程更安全。

我们注意到切换分支使用`git checkout <branch>`，而前面讲过的撤销修改则是`git checkout -- <file>`，同一个命令，有两种作用，确实有点令人迷惑。

实际上，切换分支这个动作，用`switch`更科学。因此，最新版本的Git提供了新的`git switch`命令来切换分支：

创建并切换到新的`dev`分支，可以使用：

```
$ git switch -c dev
```

直接切换到已有的`master`分支，可以使用：

```
$ git switch master
```

使用新的`git switch`命令，比`git checkout`要更容易理解。

### 小结

`git init`命令把这个目录变成Git可以管理的仓库

把文件添加到仓库：`git add test.txt`

命令`git commit -m'提交文件'`把文件提交到仓库：

Git鼓励大量使用分支：

查看分支：`git branch`

创建分支：`git branch <name>`

切换分支：`git checkout <name>`或者`git switch <name>`

创建+切换分支：`git checkout -b <name>`或者`git switch -c <name>`

合并某分支到当前分支：`git merge <name>`

删除分支：`git branch -d <name>`

###### 删除github仓库的内容

https://blog.csdn.net/Seciss/article/details/120957382

1. 新建文件夹
2. git bash here
   在新建的文件夹里右键git bash here打开终端，并执行git init初始化仓库
3. dir查看此文件夹下的文件和目录（文件夹）
4. git rm 删除本地仓库文件 **git rm** ，是你要删除的文件名字
5. git rm -r ，文件夹的删除和文件不一样，需要多一个参数，如删除本地仓库文件夹 **git rm -r** ，是你要删除的文件夹名字
6. git commit -m
7. git checkout
8. git push

# Vue3

**npm升级** npm install -g npm@8.5.3

###### vscode 快捷键

```vue
标签名 div  <div></div>

类选择器 .red <div class="red"></div>

id选择器 #one <div id="one"></div>

交集选择器 p.red#one <p class="red" id="one"></p>

子代选择器 ul>li 
                    <ul>
                      <li></li>
                    </ul>

内部文本 ul>li{我是li的内容}
                    <ul>
                      <li>我是li的内容</li>
                    </ul>

创建多个ul>li*3
                    <ul>
                      <li></li>
                      <li></li>
                      <li></li>
                    </ul>
Alt +B 快捷默认浏览器打开
光标放到该行即可，直接ctrl+C，ctrl+v，即可在下面复制一行
选中要修改的标签，ctrl+D，重复几次，即可同时修改多个标签
多行代码向后缩进用Tab键，向前缩进用shift+Tab键
ctrl+, 快捷打开vscode的设置功能
shift + alt + A可以实现js里面的快捷键功能，html和css可以直接使用 Ctrl + /
ctrl+shift+` 快捷在vscode中打开当前文件的命令行终端
```



### vue3 新特性

###### 创建vue应用：

每个 Vue 应用都是通过 [`createApp`](https://cn.vuejs.org/api/application.html#createapp) 函数创建一个新的 **应用实例**：

```json
import { createApp } from 'vue'

const app = createApp({
  /* 根组件选项 */
})
```

我们传入 `createApp` 的对象实际上是一个组件，每个应用都需要一个“根组件”，其他组件将作为其子组件。如果你使用的是单文件组件，我们可以直接从另一个文件中导入根组件。

```json
import { createApp } from 'vue'
// 从一个单文件组件中导入根组件
import App from './App.vue'

const app = createApp(App)
```

一个待办事项 (Todos) 应用的组件树可能是这样的：

```json
App (root component)
├─ TodoList
│  └─ TodoItem
│     ├─ TodoDeleteButton
│     └─ TodoEditButton
└─ TodoFooter
   ├─ TodoClearButton
   └─ TodoStatistics
```

**挂载应用**

应用实例必须在调用了 `.mount()` 方法后才会渲染出来。该方法接收一个“容器”参数，可以是一个实际的 DOM 元素或是一个 CSS 选择器字符串：

```html
<div id="app"></div>
```

```json
app.mount('#app')
```

应用根组件的内容将会被渲染在容器元素里面。容器元素自己将**不会**被视为应用的一部分。

`.mount()` 方法应该始终在整个应用配置和资源注册完成后被调用。同时请注意，不同于其他资源注册方法，它的返回值是根组件实例而非应用实例。

**DOM 中的根组件模板**

当在未采用构建流程的情况下使用 Vue 时，我们可以在挂载容器中直接书写根组件模板：

```html
<div id="app">
  <button @click="count++">{{ count }}</button>
</div>
```

```json
import { createApp } from 'vue'

const app = createApp({
  data() {
    return {
      count: 0
    }
  }
})

app.mount('#app')
```

当根组件没有设置 `template` 选项时，Vue 将自动使用容器的 `innerHTML` 作为模板。

**应用配置**

应用实例会暴露一个 `.config` 对象允许我们配置一些应用级的选项，例如定义一个应用级的错误处理器，用来捕获所有子组件上的错误：

```json
app.config.errorHandler = (err) => {
  /* 处理错误 */
}
```

应用实例还提供了一些方法来注册应用范围内可用的资源，例如注册一个组件：

```json
app.component('TodoDeleteButton', TodoDeleteButton)
```

这使得 `TodoDeleteButton` 在应用的任何地方都是可用的。我们会在指南的后续章节中讨论关于组件和其他资源的注册。你也可以在 [API 参考](https://cn.vuejs.org/api/application.html)中浏览应用实例 API 的完整列表。

确保在挂载应用实例之前完成所有应用配置！

**多个应用实例**

应用实例并不只限于一个。`createApp` API 允许你在同一个页面中创建多个共存的 Vue 应用，而且每个应用都拥有自己的用于配置和全局资源的作用域。

```json
const app1 = createApp({
  /* ... */
})
app1.mount('#container-1')

const app2 = createApp({
  /* ... */
})
app2.mount('#container-2')
```

如果你正在使用 Vue 来增强服务端渲染 HTML，并且只想要 Vue 去控制一个大型页面中特殊的一小部分，应避免将一个单独的 Vue 应用实例挂载到整个页面上，而是应该创建多个小的应用实例，将它们分别挂载到所需的元素上去。











vue3新增：

1. `composition API`
2. 使用了 `Proxy` 代替 `Object.defineProperty()` 实现响应式
3. 全新的全家桶
4. 全新的 `TS` 支持
5. `vite`

 `options API`，也就是 `vue2` 中的开发形式的一个主要问题：

**当你的组件变得越来越复杂时，组件的可读性会变得越来越差。**

**你在完成一个组件代码时，总是需要不停的上下滚动滚轮，来查看 `data` 、`methods`、`computed` 之间的配合使用，就像下面一样**

![](D:/Projects/LearnForWork/Vue/Knowledge/资料/nodes/第三章：项目架构之搭建登录架 构解决方案与实现.assets/options api.gif)

**定义数据与使用数据被分割在组件的各个位置，导致我们需要不断地翻滚页面来查看具体的业务逻辑！**

而 `Composition API` 所期望解决的就是这么一个问题

<img src="D:/Projects/LearnForWork/Vue/Knowledge/资料/nodes/第三章：项目架构之搭建登录架 构解决方案与实现.assets/1570466251996_04-logical-concerns.jpg" alt="img" style="zoom:80%;" />

**把定义数据与使用数据的逻辑放在一起进行处理，以达到更加易读，更加方便扩展的目的！**

##### 响应式

使用了 `Proxy` 代替 `Object.defineProperty()` 实现响应式

> vue2中：由于 JavaScript 的限制（ [Object.defineProperty()](https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Global_Objects/Object/defineProperty) 的限制。），Vue **不能检测**数组和对象的变化。因为 [Object.defineProperty()](https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Global_Objects/Object/defineProperty) 是通过：**为对象属性指定描述符** 的方式来监听 **对象中某个属性的 `get` 和 `set`**。
>

什么是响应式：https://www.imooc.com/article/320582

`vue` 被称为是 **渐进式框架**，就是因为，对于 `vue` 而言，它不仅仅只有 `vue.js` 这一个核心库，还有其他的比如 [vue-router](https://next.router.vuejs.org/zh/)，[vuex](https://next.vuex.vuejs.org/zh/index.html) 等一些周边库。这些周边库和 `vue.js` 一起共同组成了 `vue` 。

`vue 3` 使用 `TypeScript` 进行了重构，其目的是 **为了防止随着应用的增长，而产生的许多潜在的运行时静态类型的错误** 。同时这也意味着以后在 `vue` 中使用 `TypeScript`-->`TS` 不再需要其他的任何工具。

`TS` 的优势主要在于 **静态类型检查和环境声明**，但同时它也会为你的项目增加复杂度。如果你的项目需要使用到以上两点，那么推荐使用 `TS` 。否则只是增加了无谓的复杂度而已。

##### vite

最后就是一个新的打包工具 [vite](https://cn.vitejs.dev/)，[vite](https://cn.vitejs.dev/) 严格来说不能算是 `vue3` 的内容，只不过它跟随 `vue3` 进行了发布所以我们这里就把它算到了新特性里面。

[vite](https://cn.vitejs.dev/) 的作用其实和 [webpack](https://webpack.docschina.org/) 是一样的，都是一个 **前端构建工具**。它区别于 `webpack` 的地方在于它完全使用了 `ES Module` 的特性，可以无需预先打包，而是采用实时编译的方式。这样让它具备了远高于 `webpack` 的启动速度和热更新速度。

但是 **成也萧何，败也萧何** 因为 `vite` 完全依赖 `ES Module` 就导致了 它无法直接对 `commonJS` 的模块化方式进行支持，必须得采用 [依赖预构建](https://cn.vitejs.dev/guide/dep-pre-bundling.html) 的形式。

目前 `vite` 还不够稳定到足够支持商用，所以如果大家只是想要尝鲜，那么没有问题。如果大家希望创建一个商用的大型项目，那么个人还是推荐更加成熟的 `webpack` 方案。

而我们当前的项目旨在构建一个 **后台前端解决方案系统**，所以我们这里依然选择了 `webpack` ，而不是 `vite`。

导入element-plus:https://jingyan.baidu.com/article/cbf0e500408a076faa2893f9.html

# 前端工程师

**HTTP协议**

- 超文本传输协议 是互联网数据传输的常见协议

- 一次http事务由 **http请求**和**http响应**构成

  ![image-20230330095852168](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230330095852168.png)

```pyth

```



# 深度学习之Pytorch框架

文档规范：https://pytorch.org/docs/ 可查看各版本文档

pytorch实现模型训练：迭代训练 【数据 模型 损失函数 优化器】

![image-20230321120205291](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230321120205291.png)

![image-20230321120257358](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230321120257358.png)

pytorch 安装：下载whl文件，登陆：https://download.pytorch.org/whl/torch_stable.html

![image-20230321121344779](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230321121344779.png)

### 张量Tensor

<img src="C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230321121849835.png" alt="image-20230321121849835" style="zoom: 80%;" /><img src="C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230321122207147.png" alt="image-20230321122207147" style="zoom:80%;" />

张量 是一个多维数组，是标量、向量、矩阵的高维拓展

<img src="C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230321123648086.png" alt="image-20230321123648086" style="zoom:90%;" />![image-20230321123700819](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230321123700819.png)

<img src="C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230321123850172.png" alt="image-20230321123850172" style="zoom: 67%;" /><img src="C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230321124504501.png" alt="image-20230321124504501" style="zoom:67%;" />

##### 创建Tensor  

- 直接创建：<img src="C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230321124820901.png" alt="image-20230321124820901" style="zoom:67%;" />![image-20230321124837068](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230321124837068.png)

![image-20230321125241859](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230321125241859.png)

![image-20230321125357677](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230321125357677.png)

 ![image-20230321125525276](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230321125525276.png)

![image-20230321125550975](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230321125550975.png)

![image-20230321125616988](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230321125616988.png)

 ![image-20230321125658109](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230321125658109.png)

![image-20230321125748401](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230321125748401.png)

![image-20230321125848948](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230321125848948.png)

![image-20230321125906221](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230321125906221.png)

![image-20230321125927893](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230321125927893.png)

 ![image-20230321125958645](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230321125958645.png) 

![image-20230321130155788](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230321130155788.png)

![image-20230321130214173](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230321130214173.png)

![image-20230321130319429](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230321130319429.png)

##### 张量操作

```python
# 张量拼接与切分 
    torch.cat(tensors,dim=0,out=None)
    '''
    功能：将张量按维度dim进行拼接
    cat不会扩张张量的维度
    tensors：张量序列
    dim：要拼接的维度
    '''
    torch.stack(tensors,dim=0,out=None)  
     '''
    功能：在新创建的维度dim上进行拼接
    stack会扩张张量的维度
    tensors：张量序列
    dim：要拼接的维度
    '''
    torch.chunk(input,chunks,dim=0) 
    '''
    功能：将张量按维度dim进行平均切分
    返回值:张量列表
	注意事项:若不能整除，最后一份张量小于
	其他张量
	input:要切分的张量
	chunks:要切分的份数
	dim:要切分的维度
    '''
    torch.split(tensor,split_size_or_sections,dim=0)
    '''
    功能:将张量按维度dim进行切分
    返回值:张量列表
    tensor:要切分的张量
    split_ size_ or_ sections :为int时，表示
    每一份的长度;为list时，按list元素 切分
    dim:要切分的维度 
    '''
    torch.index_select(input,dim,index,out=None)
    '''
    功能:在维度dim上，按index索引数据
    返回值:依index索引数据拼接的张量
    input:要索引的张量
    dim:要索引的维度
    index :要索引数据的序号
    '''
    
    t=torch.randit(0,9,size=(3,3))
    idx=torch.tensor([0,2],dtype=torch.long)# 数据类型必须是torch.long
    t_select=torch.index_select(t,dim=0,index=idx) 
    
    torch.masked_ select(input,mask,out=None)
    '''
    功能:按mask中的True进行索引
    返回值:一维张量
    input:要索引的张量
    mask:与input同形状的布尔类型张量
    '''
    torch.reshape(input,shape)
    '''
    功能:变换张量形状
    注意事项:当张量在内存中是连续时，新张量与input共享数据内存
    input:要变换的张量
    shape:新张量的形状
    '''
    torch.transpose(input,dim0,dim1)
    '''
    功能:交换张量的两个维度
    input:要变换的张量
    dim0:要交换的维度
    dim1:要交换的维度
    '''
    torch.t(input)
    '''
    功能：2维张量转置，对矩阵而言，等价于torch.transpose(input,0,1)
    '''
    torch.squeeze(input,dim=None,out=None)
    '''
    功能:压缩长度为1的维度(轴)
	dim:若为None,移除所有长度为1的轴;若指定维度，当且仅当该轴长度为1时，可以被移除;
	'''
    torch.unsqueeze(input,dim,out=None)
    '''
    功能:依据dim扩展维度
    dim:扩展的维度
    '''
```

##### 张量数学运算

![image-20230321203800140](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230321203800140.png)

![image-20230321204318345](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230321204318345.png)

### 线性回归

![image-20230321204657911](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230321204657911.png)

![image-20230321204724792](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230321204724792.png)

### DataLoader

![image-20230322155906948](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230322155906948.png)

![image-20230322160001267](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230322160001267.png)

如果训练数据集有1000个样本，并且batch_size的大小为10，则dataloader的长度就是100。

<img src="C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230322160254467.png" alt="image-20230322160254467" />

<img src="C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230322160254467.png" alt="image-20230322160254467" style="zoom:80%;" />

<img src="C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20230323150418961.png" alt="image-20230323150418961" style="zoom:67%;" />



